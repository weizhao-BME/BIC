{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import loadmat, savemat\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def bootstrap_reg(model,x_train,y_train,x_test,y_test, times = 100):\n",
    "    '''\n",
    "    Perform bootstrapping, store results for further analysis and visualization\n",
    "    :param x_train: training set X\n",
    "    :param y_train: training set Y\n",
    "    :param x_test: testing set X\n",
    "    :param y_test: testing set Y\n",
    "    :param featrue_eng: feature engineering method list to pass in feature engineering function\n",
    "    :param times: how many times to bootstrap\n",
    "    :return: dictionary of metrics, dict['<metric name>'] = [<values, length = fold>]\n",
    "    '''\n",
    "    mae_results = []\n",
    "    rmse_results =[]\n",
    "    r2_results = []\n",
    "    pearson_results = []\n",
    "    spearman_results =[]\n",
    "    index = np.arange(x_train.shape[0])\n",
    "    for i in range(times):\n",
    "        boot_index = resample(index, replace=True, n_samples=None, random_state=9001+i)\n",
    "        x_boot, y_boot = x_train[boot_index], y_train[boot_index]\n",
    "        model.fit(x_boot,y_boot)\n",
    "        y_true = y_test.reshape(-1,)\n",
    "        y_preds = model.predict(x_test).reshape(-1,)\n",
    "        \n",
    "        mae = mean_absolute_error(y_true, y_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_preds))\n",
    "        r2 = r2_score(y_true, y_preds)\n",
    "        p_cor, p_p = pearsonr(y_true,y_preds)\n",
    "        sp_cor, sp_p = spearmanr(y_true, y_preds)\n",
    "        mae_results.append(mae)\n",
    "        rmse_results.append(rmse)\n",
    "        r2_results.append(r2)\n",
    "        pearson_results.append(p_cor)\n",
    "        spearman_results.append(sp_cor)\n",
    "    \n",
    "    #MAE\n",
    "    mae_arr = np.array(mae_results)\n",
    "    mean_mae = np.mean(mae_arr, axis=0)\n",
    "    mae_arr_sorted = np.sort(mae_arr, axis=0)\n",
    "    ci_low = mae_arr_sorted[round(0.025 * times)]\n",
    "    ci_high = mae_arr_sorted[round(0.975 * times)]\n",
    "    mae_result = {'result': mae_arr, 'mean': mean_mae, 'CI': [ci_low, ci_high]}\n",
    "    \n",
    "\n",
    "    # RMSE\n",
    "    rmse_arr = np.array(rmse_results)\n",
    "    mean_rmse = np.mean(rmse_arr, axis=0)\n",
    "    rmse_arr_sorted = np.sort(rmse_arr, axis=0)\n",
    "    ci_low = rmse_arr_sorted[round(0.025 * times)]\n",
    "    ci_high = rmse_arr_sorted[round(0.975 * times)]\n",
    "    rmse_result = {'result': rmse_arr, 'mean': mean_rmse, 'CI': [ci_low, ci_high]}\n",
    "\n",
    "    # R2\n",
    "    r2_arr = np.array(r2_results)\n",
    "    mean_r2 = np.mean(r2_arr, axis=0)\n",
    "    r2_arr_sorted = np.sort(r2_arr, axis=0)\n",
    "    ci_low = r2_arr_sorted[round(0.025 * times)]\n",
    "    ci_high = r2_arr_sorted[round(0.975 * times)]\n",
    "    r2_result = {'result': r2_arr, 'mean': mean_r2, 'CI': [ci_low, ci_high]}\n",
    "\n",
    "    # PR\n",
    "    pearson_arr = np.array(pearson_results)\n",
    "    mean_pearson = np.mean(pearson_arr, axis=0)\n",
    "    pearson_arr_sorted = np.sort(pearson_arr, axis=0)\n",
    "    ci_low = pearson_arr_sorted[round(0.025 * times)]\n",
    "    ci_high = pearson_arr_sorted[round(0.975 * times)]\n",
    "    pearson_result = {'result': pearson_arr, 'mean': mean_pearson, 'CI': [ci_low, ci_high]}\n",
    "\n",
    "    # SR\n",
    "    spearman_arr = np.array(spearman_results)\n",
    "    mean_spearman = np.mean(spearman_arr, axis=0)\n",
    "    spearman_arr_sorted = np.sort(spearman_arr, axis=0)\n",
    "    ci_low = spearman_arr_sorted[round(0.025 * times)]\n",
    "    ci_high = spearman_arr_sorted[round(0.975 * times)]\n",
    "    #print(ci_low)\n",
    "    #print(ci_low)\n",
    "    spearman_result = {'result': spearman_arr, 'mean': mean_spearman, 'CI': [ci_low, ci_high]}\n",
    "    \n",
    "    boot_result = {'mae_result': mae_result, 'rmse_result': rmse_result,'r2_result': r2_result, 'pearson_result': pearson_result,'spearman_result': spearman_result}\n",
    "    return boot_result\n",
    "\n",
    "def _returnRow(list):\n",
    "    return ';'.join([str(i) for i in list])\n",
    "\n",
    "# Print results\n",
    "def fillTable(boot_result, digit = 4):\n",
    "    i=0\n",
    "    one_row = [str(round(boot_result['mae_result']['mean'],digit)),\n",
    "               '['+str(round(boot_result['mae_result']['CI'][0],digit))+','+str(round(boot_result['mae_result']['CI'][1],digit))+']',\n",
    "               str(round(boot_result['rmse_result']['mean'],digit)),\n",
    "               '['+str(round(boot_result['rmse_result']['CI'][0],digit))+','+str(round(boot_result['rmse_result']['CI'][1],digit))+']',\n",
    "               str(round(boot_result['r2_result']['mean'],digit)),\n",
    "               '['+str(round(boot_result['r2_result']['CI'][0],digit))+','+str(round(boot_result['r2_result']['CI'][1],digit))+']',\n",
    "               str(round(boot_result['pearson_result']['mean'],digit)),\n",
    "               '['+str(round(boot_result['pearson_result']['CI'][0],digit))+','+str(round(boot_result['pearson_result']['CI'][1],digit))+']',\n",
    "                str(round(boot_result['spearman_result']['mean'],digit)),\n",
    "               '['+str(round(boot_result['spearman_result']['CI'][0],digit))+','+str(round(boot_result['spearman_result']['CI'][1],digit))+']']\n",
    "    print(_returnRow(one_row))\n",
    "\n",
    "def saveresult(boot_result,file):\n",
    "    np.save(file+'mae.npy',boot_result['mae_result']['result'])\n",
    "    np.save(file+'rmse.npy',boot_result['rmse_result']['result'])\n",
    "    np.save(file+'r2.npy',boot_result['r2_result']['result'])\n",
    "    np.save(file+'pearson.npy',boot_result['pearson_result']['result'])\n",
    "    np.save(file+'spearman.npy',boot_result['spearman_result']['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.0601;[0.0556,0.064];0.08;[0.0743,0.0849];0.2776;[0.1874,0.3823];0.9421;[0.9421,0.9421];0.9424;[0.9424,0.9424]\n",
      "0.0244;[0.023,0.0275];0.0325;[0.0304,0.0376];0.8804;[0.8416,0.8958];0.9489;[0.9489,0.9489];0.9516;[0.9516,0.9516]\n",
      "0.0766;[0.0741,0.0787];0.0944;[0.0909,0.0975];-0.0051;[-0.0714,0.077];0.7356;[0.7356,0.7356];0.9178;[0.9178,0.9178]\n",
      "0.0585;[0.0542,0.0643];0.0826;[0.0775,0.0891];0.2294;[0.1211,0.3273];0.8429;[0.8429,0.8429];0.8202;[0.8202,0.8202]\n",
      "0.0803;[0.0736,0.0852];0.1025;[0.0959,0.1081];-0.1873;[-0.2963,-0.0161];0.8014;[0.8014,0.8014];0.8102;[0.8102,0.8102]\n",
      "0.0745;[0.0705,0.0793];0.0982;[0.094,0.1032];-0.0899;[-0.1817,0.004];0.8333;[0.8333,0.8333];0.835;[0.835,0.835]\n",
      "0.0839;[0.0606,0.0877];0.1044;[0.0714,0.1103];-0.24;[-0.3669,0.4457];0.7846;[0.7846,0.7846];0.9441;[0.9441,0.9441]\n",
      "0.0802;[0.0754,0.0838];0.0998;[0.0931,0.1052];-0.1243;[-0.2379,0.0313];0.8975;[0.8975,0.8975];0.976;[0.976,0.976]\n",
      "0.0805;[0.0739,0.0853];0.1029;[0.0965,0.1083];-0.1958;[-0.3038,-0.0289];0.7953;[0.7953,0.7953];0.8156;[0.8156,0.8156]\n",
      "0.0673;[0.0598,0.0756];0.0885;[0.08,0.0981];0.1128;[-0.0703,0.329];0.9323;[0.9323,0.9323];0.9392;[0.9392,0.9392]\n",
      "0.0583;[0.0531,0.0651];0.0824;[0.0768,0.0899];0.2323;[0.1175,0.342];0.8168;[0.8168,0.8168];0.795;[0.795,0.795]\n",
      "0.032;[0.0277,0.0408];0.041;[0.0348,0.0522];0.8087;[0.7045,0.8651];0.9463;[0.9463,0.9463];0.9475;[0.9475,0.9475]\n",
      "0.0603;[0.0558,0.0645];0.0806;[0.0749,0.0859];0.2666;[0.1748,0.3744];0.9355;[0.9355,0.9355];0.9383;[0.9383,0.9383]\n"
     ]
    }
   ],
   "source": [
    "#Dataset N -> Dataset 1, bootstrapping; MPS95\n",
    "#Load Y\n",
    "os.chdir('.\\\\Data')\n",
    "dataset1_MPS95 = np.load('dataset1_MPS95.npy')\n",
    "dataset2_MPS95 = np.load('dataset2_MPS95.npy')\n",
    "dataset3_MPS95 = np.load('dataset3_MPS95.npy')\n",
    "NHTSA_MPS95 = np.load('NHTSA_MPS95.npy')\n",
    "NASCAR_MPS95 = np.load('NASCAR_MPS95.npy')\n",
    "#Load X\n",
    "metrics  = ['BAM','BrIC','CP','GAMBIT','HIC','HIP','PRHIC','RIC','SI','PCS','lin_acc_CG_max','ang_vel_max','ang_acc_max','Damage_C','RVCI','KLC','BRIC','CIBIC']\n",
    "for metric in metrics:\n",
    "    HM1_metric = loadmat('Lab impact1_BIC.mat')[metric]\n",
    "    HM2_metric = loadmat('Lab impact2_BIC.mat')[metric]\n",
    "    NFL53_metric = loadmat('Lab impact3_BIC.mat')[metric]\n",
    "    dataset1_metric = np.row_stack((HM1_metric,HM2_metric, NFL53_metric))\n",
    "    \n",
    "    AF_metric = loadmat('CF1_BIC.mat')[metric]\n",
    "    PAC12_metric = loadmat('CF2_BIC.mat')[metric]\n",
    "    dataset2_metric = np.row_stack((AF_metric, PAC12_metric))\n",
    "    \n",
    "    MMA1_metric = loadmat('MMA1_BIC.mat')[metric]\n",
    "    MMA2_metric = loadmat('MMA2_BIC.mat')[metric]\n",
    "    dataset3_metric = np.row_stack((MMA1_metric, MMA2_metric))\n",
    "    \n",
    "    NHTSA_metric = loadmat('NHTSA_BIC.mat')['BIC'][metric].astype(np.double)\n",
    "    NASCAR_metric = loadmat('NASCAR_BIC.mat')['BIC'][metric].astype(np.double)\n",
    "    \n",
    "    y_train= np.row_stack((dataset2_MPS95,dataset3_MPS95,NHTSA_MPS95,NASCAR_MPS95))\n",
    "    y_test = dataset1_MPS95\n",
    "    x_train = np.row_stack((dataset2_metric,dataset3_metric,NHTSA_metric,NASCAR_metric))\n",
    "    x_test = dataset1_metric\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    boot_result = bootstrap_reg(lr,x_train,y_train,x_test,y_test, times = 100)\n",
    "    fillTable(boot_result,digit = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###---Similar codes for other datasets---###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
